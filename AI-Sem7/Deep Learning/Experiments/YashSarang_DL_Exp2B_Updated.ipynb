{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyP/MvzBdkYlVZkjyo7nnQ4j"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Backpropagation algorithm to train a DNN with at least 2 hidden layers"],"metadata":{"id":"u0780TUvID5b"}},{"cell_type":"code","source":["import numpy as np\n","import tensorflow as tf\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense\n","\n","# Sample data\n","X = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n","y = np.array([[0], [1], [1], [0]])  # Reshape y to have the same shape as predictions\n","\n","# Define the model architecture with 2 hidden layers\n","model = Sequential([\n","    Dense(4, activation='sigmoid', input_shape=(2,), use_bias=True),  # Hidden layer 1\n","    Dense(3, activation='sigmoid', use_bias=True),  # Hidden layer 2\n","    Dense(1, activation='sigmoid', use_bias=True)  # Output layer\n","])"],"metadata":{"id":"rXsFW4ef7403","executionInfo":{"status":"ok","timestamp":1696790660815,"user_tz":-330,"elapsed":362,"user":{"displayName":"YASH SARANG","userId":"15963362389445961957"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["\n","# Print the weight matrices\n","print(\"Weight matrix for the first hidden layer:\")\n","print(model.layers[0].get_weights()[0])  # Weight matrix for the first hidden layer\n","\n","print(\"\\nWeight matrix for the second hidden layer:\")\n","print(model.layers[1].get_weights()[0])  # Weight matrix for the second hidden layer\n","\n","print(\"\\nWeight matrix for the output layer:\")\n","print(model.layers[2].get_weights()[0])  # Weight matrix for the output layer\n","\n","# Compile the model\n","model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n","\n","# Forward pass\n","print(\"\\nForward pass:\")\n","predictions = model.predict(X)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jTq4VC2Oj0QN","executionInfo":{"status":"ok","timestamp":1696790661791,"user_tz":-330,"elapsed":600,"user":{"displayName":"YASH SARANG","userId":"15963362389445961957"}},"outputId":"5c0ed639-80ae-4b88-e7ca-fd148253bc27"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Weight matrix for the first hidden layer:\n","[[-0.78729033  0.006212   -0.5591965  -0.05758548]\n"," [ 0.32690096  0.526803    0.7465787  -0.39513445]]\n","\n","Weight matrix for the second hidden layer:\n","[[ 0.84281516 -0.54980505 -0.915432  ]\n"," [ 0.7523217  -0.44807306 -0.04471183]\n"," [-0.3289116  -0.86866003 -0.35557324]\n"," [-0.7707951   0.5930033  -0.66535044]]\n","\n","Weight matrix for the output layer:\n","[[-0.5371624 ]\n"," [ 0.8769561 ]\n"," [ 0.70627594]]\n","\n","Forward pass:\n","1/1 [==============================] - 0s 99ms/step\n"]}]},{"cell_type":"code","source":["\n","# Backward pass\n","print(\"\\nBackward pass (Gradients):\")\n","with tf.GradientTape(persistent=True) as tape:\n","    tape.watch(model.trainable_variables)\n","    predictions = model(X)\n","    loss = tf.keras.losses.binary_crossentropy(y, predictions)\n","\n","gradients = tape.gradient(loss, model.trainable_variables)\n","for grad, var in zip(gradients, model.trainable_variables):\n","    print(f\"Gradient for {var.name}:\\n{grad}\\n\")\n","\n","# Clean up the resources used by the tape\n","del tape\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"X4tidGZpjy1O","executionInfo":{"status":"ok","timestamp":1696790661791,"user_tz":-330,"elapsed":5,"user":{"displayName":"YASH SARANG","userId":"15963362389445961957"}},"outputId":"8055d874-6bdb-4d92-f404-a8b253caf51e"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Backward pass (Gradients):\n","Gradient for dense_9/kernel:0:\n","[[-0.01164253 -0.00270888 -0.00474305  0.00154413]\n"," [-0.00769512 -0.0041979  -0.00745365  0.00196611]]\n","\n","Gradient for dense_9/bias:0:\n","[-0.02141561 -0.00925054 -0.01274958  0.00589681]\n","\n","Gradient for dense_10/kernel:0:\n","[[-0.01054475  0.01809997  0.01202418]\n"," [-0.01419787  0.02259003  0.01634984]\n"," [-0.0131081   0.02209544  0.01545649]\n"," [-0.01163798  0.01767012  0.01218858]]\n","\n","Gradient for dense_10/bias:0:\n","[-0.0256506   0.03973743  0.02814765]\n","\n","Gradient for dense_11/kernel:0:\n","[[0.10601144]\n"," [0.0639274 ]\n"," [0.05544607]]\n","\n","Gradient for dense_11/bias:0:\n","[0.18959236]\n","\n"]}]}]}