{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPUnBTxrvGYhhQ9ynOuqcRZ"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["import string\n","from nltk.tokenize import word_tokenize\n","from nltk.corpus import stopwords\n","import nltk\n","nltk.download('punkt')\n","nltk.download('stopwords')\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iNAWxlrYzN5v","executionInfo":{"status":"ok","timestamp":1693220567111,"user_tz":-330,"elapsed":595,"user":{"displayName":"YASH SARANG","userId":"15963362389445961957"}},"outputId":"a4e24f9b-4446-48c0-b405-736d5d3016fb"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n","[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":10}]},{"cell_type":"code","source":["\n","def tokenize_text(text):\n","    tokens = word_tokenize(text)  # Tokenize into words\n","    return tokens\n"],"metadata":{"id":"DALf5j8uzPEe","executionInfo":{"status":"ok","timestamp":1693220567112,"user_tz":-330,"elapsed":2,"user":{"displayName":"YASH SARANG","userId":"15963362389445961957"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["\n","def filter_tokens(tokens):\n","    filtered_tokens = []\n","    stop_words = set(stopwords.words(\"english\"))  # Load English stopwords\n","\n","    for token in tokens:\n","        token = token.lower()  # Convert token to lowercase\n","        if token not in stop_words and token not in string.punctuation:\n","            filtered_tokens.append(token)\n","\n","    return filtered_tokens\n","\n"],"metadata":{"id":"jVPx315WzQ-e","executionInfo":{"status":"ok","timestamp":1693220567533,"user_tz":-330,"elapsed":4,"user":{"displayName":"YASH SARANG","userId":"15963362389445961957"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["\n","# Example text\n","text = \"I love to read books. मुझे पढ़ना पसंद है.\"\n","tokens = tokenize_text(text)\n","filtered_tokens = filter_tokens(tokens)\n","\n","print(\"Original Tokens:\", tokens)\n","print(\"Filtered Tokens:\", filtered_tokens)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wu7eN95kzSZf","executionInfo":{"status":"ok","timestamp":1693220567533,"user_tz":-330,"elapsed":3,"user":{"displayName":"YASH SARANG","userId":"15963362389445961957"}},"outputId":"b202c9ed-dbc5-4a21-8a6e-dc0316812974"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["Original Tokens: ['I', 'love', 'to', 'read', 'books', '.', 'मुझे', 'पढ़ना', 'पसंद', 'है', '.']\n","Filtered Tokens: ['love', 'read', 'books', 'मुझे', 'पढ़ना', 'पसंद', 'है']\n"]}]}]}